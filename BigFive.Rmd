---
title: 'Mathematics of Data Scienece: \n A review of the Big Five'
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
	error = FALSE,
	warning = FALSE
	)
```

# Introduction
The [Big Five](https://en.wikipedia.org/wiki/Big_Five_personality_traits) is a model in psychology that attempts to describe a person's personality by breaking personality down into 5 dimensions.
The basic assumption is the [lexical hypothesis](https://en.wikipedia.org/wiki/Lexical_hypothesis), which states that the adjectives of a language fundamentally describe the personality.

For personality assessment, a [questionnaire](https://www.kaggle.com/tunguz/big-five-personality-test) with 50 questions (10 questions per factor) was developed, which was filled out over 500000 times (see last chapter for a description).   
We want to examine whether this data is consistent with the theory of the "Big Five".


```{r get_ready, include=FALSE}
library(tidyverse)
library(reshape2)
library(ggplot2)
library(parameters)
library(psych)
library(psycho)


N <- 1000000 # max number of observations used (computational savings)
use.timeinfo <- FALSE # use also time spend on questions (log-transformed)
do.scale <- use.timeinfo # scale collumns according to variance
                         # only scale if time is included, the rest is already
                         # nicely bounded between 1 and 5
options("digits"=2)

# Load and prepare data
  full_data <- read.csv("data-final.csv", sep="\t", header=TRUE)
  str(full_data)
  cols <- names(full_data)
  
  # for max cleanness it is recommendet to consider only "IPC"==1
  ind_IPC.is.1 <- which(full_data[,"IPC"]==1)
  N_IPC.is.1 <- length(ind_IPC.is.1)
  N <- min(N_IPC.is.1,N)
  set.seed(654321)
  ind <- sample(which(full_data[,"IPC"]==1), size=N, replace=FALSE)
  cols <- cols[1:100] #remove irrelevant(administrative) info
  if(use.timeinfo){
    data <- sapply(full_data[ind, cols], as.numeric)
    data[, 51:100] <- log(data[, 51:100]+1)
  } else { # only use ratings on questions
    cols <- cols[1:50]
    data <- sapply(full_data[ind, cols], as.numeric)
  }
  data <- data[complete.cases(data),] # remove rows with NA
  cat("Analyis will be done with N =", nrow(data),
      "\nremoved", N-nrow(data), "Observations due to missing values")
  
  #center and scale data
  Mu <- colMeans(data)
  data <- t(t(data) - Mu)
  if(do.scale)
    data <- scale(data)
```

# Analysis
To get a low-rank approximation of the personalities, we choose the approach of a truncated SVD. For this we first form the SVD and inspect the singular values:

```{r}
# Perform SVD
  SVD <- svd(data)
  #str(SVD)
  plot(SVD$d,ylim=c(0,max(SVD$d)), ylab="Singular Values")
```

Contrary to our hopes, the singular values do not converge (very quickly) towards 0. Therefore, we conclude that we can approximate the data only moderately well.

To find the appropriate number of dimensions to use when approximating the data, there is no obvious method. Different techniques [(see Wikipedia)](https://en.wikipedia.org/wiki/Exploratory_factor_analysis#Cattell's_(1966)_scree_plot) yield different recommendations:

```{r}
# inquire no of factors to use
  # K1 rule  (no. of factors == #{evals>1})
  temp <- cor(data)
  
  n <- n_factors(as.data.frame(data))
  n
  as.data.frame(n)
```

Surprisingly, in this dataset (created with the assumption of 5 factors) it is recommended to use a 6 dimensional approximation. Indeed, there is also a more recent 6-factor model (c.f. [HEXACO](https://en.wikipedia.org/wiki/HEXACO_model_of_personality_structure)).

## Analyzing right singular vectors
Now we want to inspect whether our low dimensional approximation also recovers the Big five. Since in our data set each observation corresponds to a row of $X=U\Sigma V^T \in \mathbb{R}^{n\times p}$ (not column), the principal factors are given by the columns of $V$. Thus, we plot the columns of $V$ which are associated with the 10 largest singular values.
```{r}
# Visualize most important vectors
  k <- 10
  V <- SVD$v[,1:k]
  
  gg <- melt(V, id="id")
  names(gg) <- c("Qestion_nr","Vector", "value")
  ggplot(gg, aes(x=Qestion_nr,y=Vector,fill=value))+
    geom_tile()+
    scale_fill_gradient(low="#FFFF00",high="#FF0000")+
    coord_fixed()
```

To adjust for the fact that the factors have a different influence, we multiply each vector by its singular value:
```{r}
V. <- t(t(V)*SVD$d[1:k])
  gg. <- melt(V., id="id")
  names(gg.) <- c("Qestion_nr","Vector", "value")
  ggplot(gg., aes(x=Qestion_nr,y=Vector,fill=value))+
    geom_tile()+
    scale_fill_gradient(low="#FFFF00",high="#FF0000")+
    coord_fixed()
  
  # SVD$v %*% t(SVD$v)
  # t(V) %*% V
```

We recall that the first 10 questionnaire questions were designed for the first category, the next 10 for the second, and so on. Moreover, we notice that the questions are not asked in a uniform way. For example, EXT1: "I am the life of the party." and EXT2: "I don't talk a lot." are similar questions, but the answers are (expected to be) exactly opposite. Hence assuming the the BigFive model, we expect to recover the categories in the vectors.    
For the first vector we can observe a salient signal in the first category, for the third vector in the fourth category, and for the fourth vector in the fifth category. For categories two and three, on the other hand, we cannot clearly identify a vector. 

It should be said that an intuitive view is not reason enough to reject the whole theory. However, if our criticism is justified, we could reject the question list.

*Remark:* It is possible to successfully recover all the categories by (ortogonally) rotating the factors. However in our case it feels like cheating, since we would not expect the answers for category $i$ influence the $j$-th Factor (for $i\neq j$).  
```{r}
# check_factorstructure(data)
  # just as in our plot before
  eda <- psych::fa(temp, nfactors = 5, rotate="none") %>%
    model_parameters(sort = FALSE, threshold = "max")
  
  # rotated version recovers all the categories
  eda <- psych::fa(temp, nfactors = 5, rotate="varimax") %>%
    model_parameters(sort = FALSE, threshold = "max")
```


# Clustering of questions
```{r include=FALSE}
################################
# clustering of questions
###############################
  library(rdist)
  summary(data)
  pdist(t(data[1:1000,]))
  dist <- pdist(t(data[1:1000,]),metric="absolute_correlation")^2
```

We expect answers from questions in a category to be highly correlated with each other. Consequently, we plot the correlation matrix:
```{r}
# correlation Matrix
  diag(dist) <- NA
  gg <- melt(1-dist, id="id")
  names(gg) <- c("x","y", "value")
  ggplot(gg, aes(x=x,y=y,fill=value))+
    geom_tile()+
    scale_fill_gradient(low="#FFFF00",high="#FF0000")+
    coord_fixed()
  
  # eps <- 100
  # dist2 <- 1 / (1-dist)
  # W <- exp(-dist2/eps)
  # # adjency matrix
  # gg <- melt(W, id="id")
  # names(gg) <- c("x","y", "value")
  # ggplot(gg, aes(x=x,y=y,fill=value))+
  #   geom_tile()+
  #   scale_fill_gradient(low="#FFFF00",high="#FF0000")+
  #   coord_fixed()
  # 
```
Again, we can more or less recognize the categories. However, we see a surprising amount of correlation between the categories. Thus, if we estimate each factor coefficient using only questions from the corresponding category (i.e. no rotation), this contradicts a basic assumption of the BigFive (orthogonality of factors). 

# Survey Description
```
This data was collected (2016-2018) through an interactive on-line personality test.
The personality test was constructed with the "Big-Five Factor Markers" from the IPIP. https://ipip.ori.org/newBigFive5broadKey.htm
Participants were informed that their responses would be recorded and used for research at the beginning of the test, and asked to confirm their consent at the end of the test.

The following items were presented on one page and each was rated on a five point scale using radio buttons. The order on page was was EXT1, AGR1, CSN1, EST1, OPN1, EXT2, etc.
The scale was labeled 1=Disagree, 3=Neutral, 5=Agree

EXT1	I am the life of the party.
EXT2	I don't talk a lot.
EXT3	I feel comfortable around people.
EXT4	I keep in the background.
EXT5	I start conversations.
EXT6	I have little to say.
EXT7	I talk to a lot of different people at parties.
EXT8	I don't like to draw attention to myself.
EXT9	I don't mind being the center of attention.
EXT10	I am quiet around strangers.
EST1	I get stressed out easily.
EST2	I am relaxed most of the time.
EST3	I worry about things.
EST4	I seldom feel blue.
EST5	I am easily disturbed.
EST6	I get upset easily.
EST7	I change my mood a lot.
EST8	I have frequent mood swings.
EST9	I get irritated easily.
EST10	I often feel blue.
AGR1	I feel little concern for others.
AGR2	I am interested in people.
AGR3	I insult people.
AGR4	I sympathize with others' feelings.
AGR5	I am not interested in other people's problems.
AGR6	I have a soft heart.
AGR7	I am not really interested in others.
AGR8	I take time out for others.
AGR9	I feel others' emotions.
AGR10	I make people feel at ease.
CSN1	I am always prepared.
CSN2	I leave my belongings around.
CSN3	I pay attention to details.
CSN4	I make a mess of things.
CSN5	I get chores done right away.
CSN6	I often forget to put things back in their proper place.
CSN7	I like order.
CSN8	I shirk my duties.
CSN9	I follow a schedule.
CSN10	I am exacting in my work.
OPN1	I have a rich vocabulary.
OPN2	I have difficulty understanding abstract ideas.
OPN3	I have a vivid imagination.
OPN4	I am not interested in abstract ideas.
OPN5	I have excellent ideas.
OPN6	I do not have a good imagination.
OPN7	I am quick to understand things.
OPN8	I use difficult words.
OPN9	I spend time reflecting on things.
OPN10	I am full of ideas.
```